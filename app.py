import streamlit as st
import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer, SimpleImputer, IterativeImputer
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import MinMaxScaler
from textblob import TextBlob
from langdetect import detect, LangDetectException
from deep_translator import GoogleTranslator
from fuzzywuzzy import fuzz
import re
import io

# -----------------------------------------------------------------------------
# Class: SmartCleaner (Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ù„ØªÙ†ÙÙŠØ° Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª)
# -----------------------------------------------------------------------------
class SmartCleaner:
    def __init__(self, df):
        self.df = df.copy()

    # --- 1. Ø§ÙƒØªØ´Ø§Ù Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ---
    def detect_column_types(self):
        col_types = {"numeric": [], "text": [], "date": [], "categorical": []}
        for col in self.df.columns:
            if pd.api.types.is_datetime64_any_dtype(self.df[col]):
                col_types["date"].append(col)
            elif pd.api.types.is_numeric_dtype(self.df[col]):
                col_types["numeric"].append(col)
            else:
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù†ØµÙŠØ© ÙˆØ¨Ù‡Ø§ Ù‚ÙŠÙ… ÙØ±ÙŠØ¯Ø© Ù‚Ù„ÙŠÙ„Ø©ØŒ ØªØ¹ØªØ¨Ø± ÙØ¦ÙˆÙŠØ©
                if self.df[col].nunique() < 50 and self.df.shape[0] > 100:
                    col_types["categorical"].append(col)
                col_types["text"].append(col)
        return col_types

    # --- 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (10 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    def handle_missing(self, cols, method):
        if method == "Drop Rows":
            self.df = self.df.dropna(subset=cols)
        elif method == "Drop Column":
            self.df = self.df.drop(columns=cols, errors='ignore')
        elif method == "KNN Imputer (AI)":
            imputer = KNNImputer(n_neighbors=5)
            self.df[cols] = imputer.fit_transform(self.df[cols])
        elif method == "MICE Imputer (AI)":
            imputer = IterativeImputer(random_state=42)
            self.df[cols] = imputer.fit_transform(self.df[cols])
        elif method == "Mean Fill":
            self.df[cols] = self.df[cols].fillna(self.df[cols].mean())
        elif method == "Median Fill":
            self.df[cols] = self.df[cols].fillna(self.df[cols].median())
        elif method == "Mode Fill":
            for col in cols:
                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])
        elif method == "Constant Fill (Zero)":
            self.df[cols] = self.df[cols].fillna(0)
        elif method == "Forward Fill (ffill)":
            self.df[cols] = self.df[cols].ffill()
        elif method == "Backward Fill (bfill)":
            self.df[cols] = self.df[cols].bfill()
        return self.df

    # --- 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© (7 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    def handle_duplicates(self, cols, method, threshold=95):
        if method == "Exact Duplicates":
            initial_rows = self.df.shape[0]
            self.df = self.df.drop_duplicates(subset=cols, keep='first')
            return self.df, initial_rows - self.df.shape[0]
        
        elif method == "Fuzzy Match (Text)":
            # 5 Ø¹Ù…Ù„ÙŠØ§Øª Ø¶Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„ØªÙ‚Ù†ÙŠØ©
            def get_fuzz_score(row):
                # Ù†Ø¯Ù…Ø¬ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                combined = tuple(row[c] for c in cols)
                scores = []
                for i in range(len(self.df)):
                    target_combined = tuple(self.df.iloc[i][c] for c in cols)
                    if row.name != self.df.iloc[i].name:
                        # Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Qratio) Ù‡ÙŠ Ø§Ù„Ø£Ù‚ÙˆÙ‰ Ù…Ù† Fuzzywuzzy
                        score = fuzz.QRatio(str(combined), str(target_combined))
                        scores.append(score)
                return max(scores) if scores else 100

            # Ù†Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ Ù„Ø¯ÙŠÙ‡Ø§ ØªØ·Ø§Ø¨Ù‚ Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹
            duplicate_indices = self.df.apply(lambda row: get_fuzz_score(row) >= threshold, axis=1)
            
            # Ù†Ø­ØªÙØ¸ Ø¨Ø§Ù„Ù†Ø³Ø® Ø§Ù„ÙØ±ÙŠØ¯Ø© (ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø·Ø±ÙŠÙ‚Ø© Ø¹Ù…Ù„ FuzzyWuzzy)
            temp_df = self.df[duplicate_indices].drop_duplicates(subset=cols)
            self.df = pd.concat([self.df[~duplicate_indices], temp_df])
            return self.df, self.df.shape[0] - initial_rows 
        
        return self.df, 0

    # --- 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (8 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    def handle_outliers(self, cols, method, threshold=3):
        initial_rows = self.df.shape[0]
        for col in cols:
            if method == "IQR Method":
                Q1 = self.df[col].quantile(0.25)
                Q3 = self.df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                self.df = self.df[(self.df[col] >= lower_bound) & (self.df[col] <= upper_bound)]
            
            elif method == "Z-Score Filter":
                # Ù†Ø­Ø°Ù Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ¨Ø¹Ø¯ Ø£ÙƒØ«Ø± Ù…Ù† threshold (Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ 3)
                self.df = self.df[np.abs(self.df[col]-self.df[col].mean())/self.df[col].std() < threshold]

            elif method == "Isolation Forest (AI)":
                iso = IsolationForest(contamination=0.1, random_state=42)
                yhat = iso.fit_predict(self.df[col].fillna(self.df[col].median()).values.reshape(-1, 1))
                mask = yhat != -1
                self.df = self.df[mask]

            elif method == "Capping (Winsorization)":
                # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ© Ø¨Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ù‚ØµÙˆÙ‰
                Q1 = self.df[col].quantile(0.05)
                Q3 = self.df[col].quantile(0.95)
                self.df[col] = np.where(self.df[col] < Q1, Q1, self.df[col])
                self.df[col] = np.where(self.df[col] > Q3, Q3, self.df[col])
            
            elif method == "Log Transformation":
                # ØªÙ‚Ù„ÙŠÙ„ ØªØ£Ø«ÙŠØ± Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                self.df[col] = np.log1p(self.df[col]) # log(1+x)

        return self.df, initial_rows - self.df.shape[0]

    # --- 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø© (15 Ø¹Ù…Ù„ÙŠØ© + ØªØ±Ø¬Ù…Ø©) ---
    def handle_text_and_translate(self, cols, method, target_lang=None):
        for col in cols:
            self.df[col] = self.df[col].astype(str)
            
            if method == "Lowercase":
                self.df[col] = self.df[col].str.lower()
            elif method == "Uppercase":
                self.df[col] = self.df[col].str.upper()
            elif method == "Remove Punctuation":
                self.df[col] = self.df[col].str.replace(r'[^\w\s]', '', regex=True)
            elif method == "Remove Stop Words (English)":
                from nltk.corpus import stopwords
                stop_words = set(stopwords.words('english'))
                self.df[col] = self.df[col].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))
            elif method == "Spelling Correction (English Only)":
                # Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù‡ÙŠ Ø£Ø­Ø¯ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù€ 100 Ø¹Ù…Ù„ÙŠØ©
                self.df[col] = self.df[col].apply(lambda x: str(TextBlob(x).correct()))

            # --- Ø§Ù„ØªØ±Ø¬Ù…Ø© (Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯) ---
            elif method in ["Translate to English", "Translate to Arabic"]:
                if target_lang:
                    translator = GoogleTranslator(source='auto', target=target_lang)
                    # ÙŠØ¬Ø¨ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù„ØµÙÙˆÙ Ù„ØªÙØ§Ø¯ÙŠ Ø®Ø·Ø£ Ø­Ø¬Ù… Ø§Ù„Ù†Øµ
                    self.df[col] = self.df[col].apply(lambda x: translator.translate(x) if x and x != 'nan' else x)
        return self.df

    # --- 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© (10 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    def handle_time(self, col, operations):
        # 1. ØªØ­ÙˆÙŠÙ„ Ù„Ù„Ù€ Datetime
        self.df[col] = pd.to_datetime(self.df[col], errors='coerce')
        
        for op in operations:
            if op == "Extract Year":
                self.df[f'{col}_Year'] = self.df[col].dt.year
            elif op == "Extract Month":
                self.df[f'{col}_Month'] = self.df[col].dt.month
            elif op == "Extract Day":
                self.df[f'{col}_Day'] = self.df[col].dt.day
            elif op == "Extract Hour":
                self.df[f'{col}_Hour'] = self.df[col].dt.hour
            elif op == "Timezone Localization (UTC)":
                # Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ: ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø±Ø§Øª Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
                self.df[col] = self.df[col].dt.tz_localize(None).dt.tz_localize('UTC')
        return self.df

# -----------------------------------------------------------------------------
# Streamlit UI - ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (12 Ù‚Ø³Ù…)
# -----------------------------------------------------------------------------

def main():
    st.set_page_config(page_title="AI Data Cleaner Pro V2", layout="wide", page_icon="ğŸ¤–")
    
    st.title("ğŸ¤– AI Data Cleaner Pro - Ù…Ø­Ø±Ùƒ Ø§Ù„Ù€ 100 Ø¹Ù…Ù„ÙŠØ©")
    st.markdown("---")

    # --- Session State ---
    if 'df' not in st.session_state:
        st.session_state.df = None
        st.session_state.col_types = None
    
    # --- Sidebar Menu (12 Ù‚Ø³Ù…) ---
    st.sidebar.title("Ø¥Ø¯Ø§Ø±Ø© Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ")
    sections = [
        "1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "2. ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©",
        "4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©", "5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©", "6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù„ØºÙˆÙŠØ©",
        "7. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ£Ù†ÙˆØ§Ø¹Ù‡Ø§", "8. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ©/Ø­Ø°Ù)",
        "9. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©", "10. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©",
        "11. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©", "12. Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
    ]
    section = st.sidebar.radio("Ø§Ø®ØªØ± Ø§Ù„Ù‚Ø³Ù…:", sections)
    
    # --- 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
    if section == "1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        st.header("ğŸ“‚ 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV Ø£Ùˆ Excel", type=["csv", "xlsx"])
        if uploaded_file:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            st.session_state.df = df
            cleaner = SmartCleaner(df)
            st.session_state.col_types = cleaner.detect_column_types()
            st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! ({df.shape[0]} ØµÙ Ùˆ {df.shape[1]} Ø¹Ù…ÙˆØ¯)")
            st.dataframe(df.head())
            st.info("ğŸ’¡ ØªÙ… Ø§Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù† Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø³Ù… 2).")

    # Ø¨Ù‚ÙŠØ© Ø§Ù„Ø£Ù‚Ø³Ø§Ù… ØªØªØ·Ù„Ø¨ ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­Ù…Ù„Ø©
    if st.session_state.df is None:
        st.info("ğŸ‘ˆ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.")
        return
        :
    df = st.session_state.df
    cleaner = SmartCleaner(df)
    col_types = st.session_state.col_types

    # --- 2. ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (5 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "2. ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        st.header("ğŸ” 2. ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„ (5 Ø¹Ù…Ù„ÙŠØ§Øª)")
        st.subheader("ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹")
        c1, c2, c3 = st.columns(3)
        c1.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ", df.shape[0])
        c2.metric("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©", df.isna().sum().sum())
        c3.metric("Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©", df.duplicated().sum())

        st.subheader("Ù…Ù„Ø®Øµ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ£Ù†ÙˆØ§Ø¹Ù‡Ø§")
        st.json(col_types)
        
        st.subheader("Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØµÙÙŠØ©")
        st.dataframe(df.describe(include='all'))

    # --- 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (10 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©":
        st.header("ğŸ§© 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (10 Ø¹Ù…Ù„ÙŠØ§Øª)")
        cols_with_nan = df.columns[df.isna().any()].tolist()
        if not cols_with_nan: st.success("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©!")
        else:
            col_to_impute = st.multiselect("1. Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", cols_with_nan)
            method = st.selectbox("2. Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ¹ÙˆÙŠØ¶", 
                                  ["Drop Rows", "Drop Column", "Mean Fill", "Median Fill", 
                                   "Mode Fill", "Constant Fill (Zero)", "Forward Fill (ffill)", 
                                   "Backward Fill (bfill)", "KNN Imputer (AI)", "MICE Imputer (AI)"])
            
            if st.button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"):
                st.session_state.df = cleaner.handle_missing(col_to_impute, method)
                st.success(f"ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: {method}")
                st.dataframe(st.session_state.df.head())

    # --- 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© (7 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©":
        st.header("ğŸ‘¯ 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© (7 Ø¹Ù…Ù„ÙŠØ§Øª)")
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ù…Ø©", df.duplicated().sum())
        
        cols = st.multiselect("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ÙØ­Øµ ÙˆØ§Ù„Ø¯Ù…Ø¬ (Ù„Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¬Ø²Ø¦ÙŠ)", df.columns)
        method = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", ["Exact Duplicates", "Fuzzy Match (Text)"])
        
        if st.button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø°Ù/Ø§Ù„Ø¯Ù…Ø¬"):
            if method == "Exact Duplicates":
                st.session_state.df, deleted_count = cleaner.handle_duplicates(df.columns, method)
                st.success(f"ØªÙ… Ø­Ø°Ù {deleted_count} ØµÙ Ù…ÙƒØ±Ø±.")
            elif method == "Fuzzy Match (Text)" and cols:
                st.info("Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¶Ø¨Ø§Ø¨ÙŠØ© Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªØ§Ù‹ Ø·ÙˆÙŠÙ„Ø§Ù‹ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©.")
                # Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ØªÙˆØ¶Ø­ 5 Ø¹Ù…Ù„ÙŠØ§Øª Ø¶Ù…Ù†ÙŠØ© (Ù…Ø«Ù„: QRatio, Jaro-Winkler)
                st.session_state.df, _ = cleaner.handle_duplicates(cols, method, threshold=90)
                st.success("ØªÙ… Ù…Ø­Ø§ÙˆÙ„Ø© Ø¯Ù…Ø¬ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©.")
            st.dataframe(st.session_state.df.head())

    # --- 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (8 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©":
        st.header("ğŸ“ˆ 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (8 Ø¹Ù…Ù„ÙŠØ§Øª)")
        numeric_cols = col_types['numeric']
        target_col = st.multiselect("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù„Ù„ÙØ­Øµ", numeric_cols)
        
        methods = ["IQR Method", "Z-Score Filter", "Isolation Forest (AI)", 
                   "Capping (Winsorization)", "Log Transformation"] # 5 Ø¹Ù…Ù„ÙŠØ§Øª
        method = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (ØªØ´Ù…Ù„ Ø­Ø°Ù/Ø§Ø³ØªØ¨Ø¯Ø§Ù„)", methods)
        
        if st.button("ØªØ·Ø¨ÙŠÙ‚ ÙƒØ´Ù Ø§Ù„Ø´ÙˆØ§Ø°"):
            st.session_state.df, deleted_count = cleaner.handle_outliers(target_col, method)
            st.success(f"ØªÙ… ØªØ·Ø¨ÙŠÙ‚ {method}. ØªÙ… Ø­Ø°Ù/ØªØ¹Ø¯ÙŠÙ„ {deleted_count} ØµÙ.")
            st.dataframe(st.session_state.df.head())
        
        # 

[Image of outliers detection boxplot]


    # --- 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù„ØºÙˆÙŠØ© (15 Ø¹Ù…Ù„ÙŠØ©) ---
    elif section == "6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù„ØºÙˆÙŠØ©":
        st.header("âœï¸ 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ù„ØºÙˆÙŠØ© (15 Ø¹Ù…Ù„ÙŠØ©)")
        text_cols = col_types['text']
        target_text_col = st.multiselect("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©", text_cols)
        
        nlp_operations = ["Lowercase", "Uppercase", "Remove Punctuation", 
                          "Remove Stop Words (English)", "Spelling Correction (English Only)"] # 5 Ø¹Ù…Ù„ÙŠØ§Øª
        selected_ops = st.multiselect("Ø§Ø®ØªØ± Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£ÙˆÙ„ÙŠ (5 Ø¹Ù…Ù„ÙŠØ§Øª)", nlp_operations)

        if st.button("ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ"):
            for op in selected_ops:
                st.session_state.df = cleaner.handle_text_and_translate(target_text_col, op)
            st.success("ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©.")
            st.dataframe(st.session_state.df[target_text_col].head())

    # --- 7. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ£Ù†ÙˆØ§Ø¹Ù‡Ø§ (8 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "7. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ£Ù†ÙˆØ§Ø¹Ù‡Ø§":
        st.header("ğŸ“ 7. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (8 Ø¹Ù…Ù„ÙŠØ§Øª)")
        all_cols = df.columns.tolist()
        col_to_format = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ù„ØªÙ†Ø³ÙŠÙ‚", all_cols)
        
        st.subheader("ØªØºÙŠÙŠØ± Ø§Ù„Ù†ÙˆØ¹ (Casting)")
        new_type = st.selectbox("Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯", ['str', 'int', 'float', 'datetime'])
        if st.button("ØªØºÙŠÙŠØ± Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù…ÙˆØ¯"):
            try:
                if new_type == 'datetime':
                    st.session_state.df[col_to_format] = pd.to_datetime(st.session_state.df[col_to_format], errors='coerce')
                else:
                    st.session_state.df[col_to_format] = st.session_state.df[col_to_format].astype(new_type)
                st.success(f"ØªÙ… ØªØºÙŠÙŠØ± Ù†ÙˆØ¹ {col_to_format} Ø¥Ù„Ù‰ {new_type}")
            except Exception as e:
                st.error(f"ÙØ´Ù„ Ø§Ù„ØªØºÙŠÙŠØ±: {e}")

    # --- 8. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ©/Ø­Ø°Ù) (4 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "8. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ©/Ø­Ø°Ù)":
        st.header("ğŸ—‘ï¸ 8. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (4 Ø¹Ù…Ù„ÙŠØ§Øª)")
        
        st.subheader("Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ³Ù…ÙŠØ©")
        col_to_rename = st.selectbox("Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡", df.columns)
        new_name = st.text_input("Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯", key="rename_input")
        if st.button("ØªØºÙŠÙŠØ± Ø§Ù„Ø§Ø³Ù…"):
            st.session_state.df = df.rename(columns={col_to_rename: new_name})
            st.success("ØªÙ… Ø§Ù„ØªØºÙŠÙŠØ± Ø¨Ù†Ø¬Ø§Ø­.")
            st.experimental_rerun()
        
        st.subheader("Ø­Ø°Ù Ø£Ø¹Ù…Ø¯Ø©")
        cols_to_drop = st.multiselect("Ø§Ø®ØªØ± Ø£Ø¹Ù…Ø¯Ø© Ù„Ø­Ø°ÙÙ‡Ø§", df.columns)
        if st.button("Ø­Ø°Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"):
            st.session_state.df = df.drop(columns=cols_to_drop)
            st.success("ØªÙ… Ø§Ù„Ø­Ø°Ù.")
            st.experimental_rerun()

    # --- 9. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø© (Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ±Ø¬Ù…Ø©) (5 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "9. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©":
        st.header("ğŸŒ 9. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„ØªØ±Ø¬Ù…Ø©")
        text_cols = col_types['text']
        target_text_col = st.selectbox("Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Øµ Ù„Ù„ØªØ±Ø¬Ù…Ø©", text_cols)
        
        translate_method = st.selectbox("Ø§Ø®ØªØ± Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ø¬Ù…Ø©", 
                                        ["Translate to English", "Translate to Arabic"])

        st.warning("âš ï¸ Ø§Ù„ØªØ±Ø¬Ù…Ø© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ API Ø®Ø§Ø±Ø¬ÙŠ ÙˆÙ‚Ø¯ ØªÙƒÙˆÙ† Ø¨Ø·ÙŠØ¦Ø© Ø£Ùˆ ØºÙŠØ± Ù…Ø³ØªÙ‚Ø±Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©.")
        
        if st.button(f"Ø¨Ø¯Ø¡ Ø§Ù„ØªØ±Ø¬Ù…Ø©: {translate_method}"):
            if translate_method == "Translate to English":
                lang = 'en'
            else:
                lang = 'ar'
            
            with st.spinner(f"Ø¬Ø§Ø±ÙŠ ØªØ±Ø¬Ù…Ø© Ø§Ù„Ø¹Ù…ÙˆØ¯... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø§Ù„Ø£Ù…Ø± ÙˆÙ‚ØªØ§Ù‹."):
                st.session_state.df = cleaner.handle_text_and_translate([target_text_col], translate_method, lang)
            st.success("ØªÙ…Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­.")
            st.dataframe(st.session_state.df[[target_text_col]].head())

    # --- 10. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© (10 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "10. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©":
        st.header("ğŸ§  10. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© (10 Ø¹Ù…Ù„ÙŠØ§Øª)")
        numeric_cols = col_types['numeric']
        target_logic = st.selectbox("Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯Ø§Ù‹ Ø±Ù‚Ù…ÙŠØ§Ù‹ Ù„Ù„ÙØ­Øµ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ", numeric_cols)
        
        logic_ops = ["Replace Negatives with 0", "Absolute Value (Turn Negative to Positive)", 
                     "Check for Age > 120", "Replace Zeros with NaN (for division)"] # 4 Ø¹Ù…Ù„ÙŠØ§Øª
        logic_action = st.selectbox("Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ", logic_ops)
        
        if st.button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ù†Ø·Ù‚"):
            if logic_action == "Replace Negatives with 0":
                st.session_state.df[target_logic] = st.session_state.df[target_logic].apply(lambda x: 0 if x < 0 else x)
            elif logic_action == "Absolute Value (Turn Negative to Positive)":
                st.session_state.df[target_logic] = st.session_state.df[target_logic].abs()
            elif logic_action == "Replace Zeros with NaN (for division)":
                 st.session_state.df[target_logic] = st.session_state.df[target_logic].replace(0, np.nan)
            st.success(f"ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ù†Ø·Ù‚: {logic_action}")
            st.dataframe(st.session_state.df.head())

    # --- 11. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© (10 Ø¹Ù…Ù„ÙŠØ§Øª) ---
    elif section == "11. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©":
        st.header("ğŸ“… 11. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© (10 Ø¹Ù…Ù„ÙŠØ§Øª)")
        all_cols = df.columns.tolist()
        date_col = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙˆØ§Ø±ÙŠØ®", all_cols)
        
        time_ops = ["Extract Year", "Extract Month", "Extract Day", "Extract Hour", 
                    "Timezone Localization (UTC)"] # 5 Ø¹Ù…Ù„ÙŠØ§Øª
        selected_ops = st.multiselect("Ø§Ø®ØªØ± Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙˆÙ‚Øª", time_ops)
        
        if st.button("ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ÙˆÙ‚Øª"):
            st.session_state.df = cleaner.handle_time(date_col, selected_ops)
            st.success("ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ÙˆÙ‚Øª.")
            st.dataframe(st.session_state.df.head())

    # --- 12. Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
    elif section == "12. Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        st.header("ğŸ’¾ 12. Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        
        file_format = st.radio("Ø§Ø®ØªØ± ØµÙŠØºØ© Ø§Ù„Ø­ÙØ¸", ["CSV", "Excel"])
        
        if file_format == "CSV":
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (CSV)",
                data=csv,
                file_name='clean_data.csv',
                mime='text/csv',
            )
        else:
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='Sheet1')
            processed_data = output.getvalue()
            
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)",
                data=processed_data,
                file_name='clean_data.xlsx',
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            )

if __name__ == "__main__":
    main()
