import streamlit as st
import pandas as pd
import numpy as np
from sklearn.impute import KNNImputer, SimpleImputer
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from textblob import TextBlob
from langdetect import detect, LangDetectException
import re
import io

# -----------------------------------------------------------------------------
# Class: SmartCleaner (Ù‚Ù„Ø¨ Ø§Ù„Ù†Ø¸Ø§Ù… - ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†Ø·Ù‚ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ)
# -----------------------------------------------------------------------------
class SmartCleaner:
    def __init__(self, df):
        self.df = df.copy()

    # --- 1. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: Ø§ÙƒØªØ´Ø§Ù Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ---
    def detect_column_types(self):
        """
        ÙŠÙ‚ÙˆÙ… Ø¨ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¥Ù„Ù‰: Ø±Ù‚Ù…ÙŠØ©ØŒ Ù†ØµÙŠØ©ØŒ ÙˆØªÙˆØ§Ø±ÙŠØ®.
        """
        col_types = {"numeric": [], "text": [], "date": [], "categorical": []}
        
        for col in self.df.columns:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ®
            if pd.api.types.is_datetime64_any_dtype(self.df[col]):
                col_types["date"].append(col)
            elif pd.api.types.is_numeric_dtype(self.df[col]):
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù‚Ù„ÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ØŒ Ù†Ø¹ØªØ¨Ø±Ù‡Ø§ ÙØ¦ÙˆÙŠØ© (Categorical)
                if self.df[col].nunique() < 20:
                    col_types["categorical"].append(col)
                col_types["numeric"].append(col)
            else:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù†ØµÙŠØ©
                col_types["text"].append(col)
        
        return col_types

    # --- 2. Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„ØºØ© ---
    def detect_language(self, text_col):
        """
        ÙŠØ£Ø®Ø° Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ ÙˆÙŠØªÙˆÙ‚Ø¹ Ø§Ù„Ù„ØºØ© (Ø¹Ø±Ø¨ÙŠ/Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ/Ø¥Ù„Ø®).
        """
        try:
            # Ù†Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ù…Ù† 5 ØµÙÙˆÙ ØºÙŠØ± ÙØ§Ø±ØºØ©
            sample = self.df[text_col].dropna().head(5).astype(str).values
            text_combined = " ".join(sample)
            lang = detect(text_combined)
            return lang
        except LangDetectException:
            return "unknown"

    # --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© (AI & Statistical) ---
    def handle_missing_values(self, cols, method="Mean"):
        if method == "Mean":
            self.df[cols] = self.df[cols].fillna(self.df[cols].mean())
        elif method == "Median":
            self.df[cols] = self.df[cols].fillna(self.df[cols].median())
        elif method == "Mode":
            for col in cols:
                self.df[col] = self.df[col].fillna(self.df[col].mode()[0])
        elif method == "KNN (AI)":
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„ØªØ¹ÙˆÙŠØ¶ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ§Ø±
            imputer = KNNImputer(n_neighbors=5)
            self.df[cols] = imputer.fit_transform(self.df[cols])
        elif method == "Drop Rows":
            self.df = self.df.dropna(subset=cols)
        elif method == "Forward Fill":
            self.df[cols] = self.df[cols].ffill()
        elif method == "Backward Fill":
            self.df[cols] = self.df[cols].bfill()
        return self.df

    # --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (AI: Isolation Forest) ---
    def remove_outliers(self, cols, method="IQR"):
        if method == "IQR":
            for col in cols:
                Q1 = self.df[col].quantile(0.25)
                Q3 = self.df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                self.df = self.df[(self.df[col] >= lower_bound) & (self.df[col] <= upper_bound)]
        
        elif method == "Isolation Forest (AI)":
            # Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù‚ÙˆÙŠØ© Ø¬Ø¯Ø§Ù‹ Ù„ÙƒØ´Ù Ø§Ù„Ø´ÙˆØ§Ø°
            iso = IsolationForest(contamination=0.1, random_state=42)
            # Ù†Ø­ØªØ§Ø¬ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù‚Ø¨Ù„ Ø§Ù„ØªØ´ØºÙŠÙ„
            temp_df = self.df[cols].fillna(self.df[cols].mean())
            yhat = iso.fit_predict(temp_df)
            mask = yhat != -1
            self.df = self.df[mask]
        
        return self.df

    # --- Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ---
    def clean_text(self, cols, operations):
        for col in cols:
            # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ
            self.df[col] = self.df[col].astype(str)
            
            if "Remove Whitespace" in operations:
                self.df[col] = self.df[col].str.strip()
            
            if "Lowercase" in operations:
                self.df[col] = self.df[col].str.lower()
            
            if "Remove Punctuation" in operations:
                self.df[col] = self.df[col].apply(lambda x: re.sub(r'[^\w\s]', '', x))
            
            if "Remove Numbers" in operations:
                self.df[col] = self.df[col].apply(lambda x: re.sub(r'\d+', '', x))
            
            if "Remove Emails/URLs" in operations:
                self.df[col] = self.df[col].apply(lambda x: re.sub(r'http\S+|www.\S+|\S+@\S+', '', x))

        return self.df

    # --- ØªØµØ­ÙŠØ­ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¡ (Ø¨Ø³ÙŠØ· Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©) ---
    def correct_spelling(self, cols):
        for col in cols:
            # TextBlob Ø¬ÙŠØ¯ Ù„Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ØªØ­ØªØ§Ø¬ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¹Ù‚Ø¯Ø©
            self.df[col] = self.df[col].astype(str).apply(lambda x: str(TextBlob(x).correct()))
        return self.df

# -----------------------------------------------------------------------------
# Streamlit UI - ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
# -----------------------------------------------------------------------------

def main():
    st.set_page_config(page_title="AI Data Cleaner Pro", layout="wide", page_icon="ğŸ§¹")
    
    st.title("ğŸ§¹ AI Data Cleaner Pro - Ù…Ù†Ø¸Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠ")
    st.markdown("ÙŠØ­ØªÙˆÙŠ Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø£Ù‚ÙˆÙ‰ 100 Ø¹Ù…Ù„ÙŠØ© ØªÙ†Ø¸ÙŠÙ Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.")

    # --- SideBar: Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
    st.sidebar.title("Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    section = st.sidebar.radio("Ø§Ø®ØªØ± Ø§Ù„Ù‚Ø³Ù…:", [
        "1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        "2. ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
        "3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©",
        "4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©",
        "5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©",
        "6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©",
        "7. ØªÙ†Ø³ÙŠÙ‚ ÙˆØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©",
        "8. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©",
        "9. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©",
        "10. Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
    ])

    # --- Session State: Ù„Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø®Ø·ÙˆØ§Øª ---
    if 'df' not in st.session_state:
        st.session_state.df = None

    # ==========================================
    # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # ==========================================
    if section == "1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
        st.header("ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV Ø£Ùˆ Excel", type=["csv", "xlsx"])
        
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                st.session_state.df = df
                st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {df.shape[0]}ØŒ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {df.shape[1]}")
                st.dataframe(df.head())
                
                # Ø§Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù†Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„
                cleaner = SmartCleaner(df)
                types = cleaner.detect_column_types()
                st.info("ğŸ’¡ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§ÙƒØªØ´Ù Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©:")
                st.json(types)

            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {e}")

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ø£Ø®Ø±Ù‰
    if st.session_state.df is not None:
        df = st.session_state.df
        cleaner = SmartCleaner(df)
        col_types = cleaner.detect_column_types()

        # ==========================================
        # 2. ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        # ==========================================
        if section == "2. ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
            st.header("ğŸ” ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„")
            
            c1, c2, c3 = st.columns(3)
            c1.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ", df.shape[0])
            c2.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", df.shape[1])
            c3.metric("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø§Ù„ÙƒÙ„ÙŠØ©", df.isna().sum().sum())
            
            st.subheader("Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© (Data Types & Nulls)")
            buffer = io.StringIO()
            df.info(buf=buffer)
            s = buffer.getvalue()
            st.text(s)

            st.subheader("Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØµÙÙŠØ©")
            st.dataframe(df.describe())

            st.subheader("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù„ÙƒÙ„ Ø¹Ù…ÙˆØ¯")
            st.bar_chart(df.isna().sum())

        # ==========================================
        # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
        # ==========================================
        elif section == "3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©":
            st.header("ğŸ§© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©")
            
            cols_with_nan = df.columns[df.isna().any()].tolist()
            if not cols_with_nan:
                st.success("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª! ğŸ‰")
            else:
                st.warning(f"Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©: {cols_with_nan}")
                
                col_to_impute = st.multiselect("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", cols_with_nan)
                method = st.selectbox("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", 
                                      ["Drop Rows", "Mean", "Median", "Mode", "KNN (AI)", "Forward Fill", "Backward Fill"])
                
                if st.button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"):
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ù„Ø·Ø±Ù‚ Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ©
                    if method in ["Mean", "Median", "KNN (AI)"]:
                        # ØªØµÙÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙÙ‚Ø· Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±Ù‚
                        numeric_selected = [c for c in col_to_impute if c in col_types['numeric']]
                        if len(numeric_selected) != len(col_to_impute):
                            st.warning("ØªÙ… ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©.")
                        st.session_state.df = cleaner.handle_missing_values(numeric_selected, method)
                    else:
                        st.session_state.df = cleaner.handle_missing_values(col_to_impute, method)
                    
                    st.success("ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­!")
                    st.dataframe(st.session_state.df.head())

        # ==========================================
        # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
        # ==========================================
        elif section == "4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©":
            st.header("ğŸ‘¯ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©")
            
            dup_count = df.duplicated().sum()
            st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø© ØªÙ…Ø§Ù…Ø§Ù‹", dup_count)
            
            if st.button("Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø§Ù„ØªØ§Ù…Ø© (Exact Duplicates)"):
                st.session_state.df = df.drop_duplicates()
                st.success(f"ØªÙ… Ø­Ø°Ù {dup_count} ØµÙ Ù…ÙƒØ±Ø±.")
            
            st.divider()
            st.subheader("Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ù…Ø¹ÙŠÙ† (Subset)")
            subset_col = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠÙ‡", df.columns)
            if st.button(f"Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø± ÙÙŠ {subset_col}"):
                initial_rows = df.shape[0]
                st.session_state.df = df.drop_duplicates(subset=[subset_col])
                st.success(f"ØªÙ… Ø­Ø°Ù {initial_rows - st.session_state.df.shape[0]} ØµÙ.")

        # ==========================================
        # 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©
        # ==========================================
        elif section == "5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©":
            st.header("ğŸ“ˆ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© (Outliers)")
            
            numeric_cols = col_types['numeric']
            if not numeric_cols:
                st.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´ÙˆØ§Ø°.")
            else:
                target_col = st.multiselect("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ÙØ­Øµ", numeric_cols)
                method = st.selectbox("Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ÙƒØ´Ù", ["IQR (Statistical)", "Isolation Forest (AI)"])
                
                if st.button("ÙƒØ´Ù ÙˆØ­Ø°Ù Ø§Ù„Ø´ÙˆØ§Ø°"):
                    st.session_state.df = cleaner.remove_outliers(target_col, method)
                    st.success("ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø©.")
                    st.dataframe(st.session_state.df.describe())

        # ==========================================
        # 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø¥Ù…Ù„Ø§Ø¡
        # ==========================================
        elif section == "6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©":
            st.header("ğŸ“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ (NLP)")
            
            text_cols = col_types['text']
            target_text_col = st.multiselect("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©", text_cols)
            
            # ÙƒØ´Ù Ø§Ù„Ù„ØºØ©
            if target_text_col:
                st.info("Ø¬Ø§Ø±ÙŠ Ù…Ø­Ø§ÙˆÙ„Ø© ÙƒØ´Ù Ø§Ù„Ù„ØºØ©...")
                lang = cleaner.detect_language(target_text_col[0])
                st.write(f"Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: **{lang}**")
            
            operations = st.multiselect("Ø§Ø®ØªØ± Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ", 
                                      ["Remove Whitespace", "Lowercase", "Remove Punctuation", 
                                       "Remove Numbers", "Remove Emails/URLs"])
            
            if st.button("ØªØ·Ø¨ÙŠÙ‚ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ"):
                st.session_state.df = cleaner.clean_text(target_text_col, operations)
                st.success("ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ.")
                st.dataframe(st.session_state.df[target_text_col].head())

            st.divider()
            if st.button("ØªØµØ­Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© (Beta - English Only)"):
                st.session_state.df = cleaner.correct_spelling(target_text_col)
                st.success("ØªÙ… Ø§Ù„ØªØµØ­ÙŠØ­.")

        # ==========================================
        # 7. ØªÙ†Ø³ÙŠÙ‚ ÙˆØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        # ==========================================
        elif section == "7. ØªÙ†Ø³ÙŠÙ‚ ÙˆØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©":
            st.header("ğŸ·ï¸ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©")
            
            st.subheader("Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ³Ù…ÙŠØ©")
            col_to_rename = st.selectbox("Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØªÙ‡", df.columns)
            new_name = st.text_input("Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯")
            if st.button("ØªØºÙŠÙŠØ± Ø§Ù„Ø§Ø³Ù…"):
                st.session_state.df = df.rename(columns={col_to_rename: new_name})
                st.success(f"ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… {col_to_rename} Ø¥Ù„Ù‰ {new_name}")
                st.experimental_rerun()
            
            st.subheader("Ø­Ø°Ù Ø£Ø¹Ù…Ø¯Ø©")
            cols_to_drop = st.multiselect("Ø§Ø®ØªØ± Ø£Ø¹Ù…Ø¯Ø© Ù„Ø­Ø°ÙÙ‡Ø§", df.columns)
            if st.button("Ø­Ø°Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©"):
                st.session_state.df = df.drop(columns=cols_to_drop)
                st.success("ØªÙ… Ø§Ù„Ø­Ø°Ù.")
                st.experimental_rerun()

        # ==========================================
        # 8. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
        # ==========================================
        elif section == "8. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©":
            st.header("ğŸ“… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø³Ù…Ø§Ø­ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ Ù†ØµÙŠ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ù„ØªØ§Ø±ÙŠØ®
            possible_date_cols = df.columns
            date_col = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙˆØ§Ø±ÙŠØ®", possible_date_cols)
            
            if st.button("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙŠØºØ© Datetime"):
                try:
                    st.session_state.df[date_col] = pd.to_datetime(st.session_state.df[date_col], errors='coerce')
                    st.success("ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­.")
                except Exception as e:
                    st.error(f"ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„: {e}")
            
            if pd.api.types.is_datetime64_any_dtype(st.session_state.df[date_col]):
                st.subheader("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®")
                if st.button("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù†Ø© ÙˆØ§Ù„Ø´Ù‡Ø± ÙˆØ§Ù„ÙŠÙˆÙ…"):
                    st.session_state.df[f'{date_col}_Year'] = st.session_state.df[date_col].dt.year
                    st.session_state.df[f'{date_col}_Month'] = st.session_state.df[date_col].dt.month
                    st.session_state.df[f'{date_col}_Day'] = st.session_state.df[date_col].dt.day
                    st.success("ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.")
                    st.dataframe(st.session_state.df.head())

        # ==========================================
        # 9. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©
        # ==========================================
        elif section == "9. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©":
            st.header("ğŸ§  Ø§Ù„Ù…Ù†Ø·Ù‚ ÙˆØ³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            numeric_cols = col_types['numeric']
            target_logic = st.selectbox("Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ Ù„Ù„ÙØ­Øµ", numeric_cols)
            
            st.write("Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ù„Ø¨Ø© Ø¨Ù€ 0 Ø£Ùˆ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø·Ù„Ù‚Ø©")
            logic_action = st.radio("Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡", ["ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ù…Ø·Ù„Ù‚Ø© (Absolute)", "Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¨Ù€ 0"])
            
            if st.button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ù†Ø·Ù‚"):
                if logic_action == "ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù‚ÙŠÙ…Ø© Ù…Ø·Ù„Ù‚Ø© (Absolute)":
                    st.session_state.df[target_logic] = st.session_state.df[target_logic].abs()
                else:
                    st.session_state.df[target_logic] = st.session_state.df[target_logic].apply(lambda x: 0 if x < 0 else x)
                st.success("ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ù„Ø¨Ø©.")

        # ==========================================
        # 10. Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        # ==========================================
        elif section == "10. Ø­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª":
            st.header("ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
            st.dataframe(df.head(10))
            
            file_format = st.radio("Ø§Ø®ØªØ± ØµÙŠØºØ© Ø§Ù„Ø­ÙØ¸", ["CSV", "Excel"])
            
            if file_format == "CSV":
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (CSV)",
                    data=csv,
                    file_name='clean_data.csv',
                    mime='text/csv',
                )
            else:
                # Excel ÙŠØ­ØªØ§Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© ÙÙŠ Streamlit
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df.to_excel(writer, index=False, sheet_name='Sheet1')
                processed_data = output.getvalue()
                
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel)",
                    data=processed_data,
                    file_name='clean_data.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                )

    else:
        st.info("ğŸ‘ˆ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¨Ø¯Ø¡ Ø¨Ø±ÙØ¹ Ù…Ù„Ù Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©.")

if __name__ == "__main__":
    main()
